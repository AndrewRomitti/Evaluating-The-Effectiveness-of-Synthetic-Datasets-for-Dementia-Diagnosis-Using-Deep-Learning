# Evaluating-The-Effectiveness-of-Synthetic-Datasets-for-Dementia-Diagnosis-Using-Deep-Learning

This is the code for the paper: Evaluating the Effectiveness of Synthetic Datasets for Dementia Diagnosis for Dementia Diagnosis Using Deep Learning. This paper was presented and published at the 2023 IEEE AIPR Workshop as one of the 15 minute presentations.

## Abstract
Early and accurate diagnosis of dementia can lead to better treatment of the disease and improve patients' quality of 
life. Advanced neuroimaging technologies such as magnetic resonance imaging (MRI) and deep learning hold promise for early and accurate dementia diagnosis. However, there is limited number of real-world MRI datasets for training deep-learning 
models to classify a patient's degree of dementia. Generative adversarial networks (GANs) are deep learning-based generative models that can generate synthetic data samples based on a real dataset's data distribution. They have been successfully used in clinical neuroimaging studies. In this work, we investigate how synthetic MRI images generated by GANs can improve the performance of deep learning models for accurately classifying the level of dementia (i.e., very mildly demented, mildly demented, moderately demented, and no dementia.) We trained a state-ofthe-art deep learning model for image classification, namely, the Data-Efficient Image Transformer (DeiT) using a real-world MRI dataset along with synthetic MRI images generated by GANs. We combined real and synthetic images during training by varying the proportion of synthetic images in the training set. We evaluated the accuracy and F1-score of the trained DeiT models on real MRI 
images. Our results showed that DeiT can achieve good performance even with synthetic images in the training set. Hence, GANs can offer a promising solution to improving dementia diagnosis via deep learning especially when real data are scarce.

## Code
The code was run on CloudLab, an experimental testbed for cloud computing research. The code was run on a bare metal machine with one NVIDIA P100 GPU (12GB RAM) for approximately 5 days. The code inside of this repo was what was run in the CloudLab environment 


### GAN Training/Setup
To run the code to create the stylegan network, ensure that you have a kaggle.json file in your home directory. Additionally, make sure that your library versions correspond with stylegan3's recommendations on their repo: https://github.com/NVlabs/stylegan3

```
bash train_gan.sh
```
While the paper trained the GAN on 3000 kimgs, this code will train it for the ideal 5000 kimgs to replicate ideal results. If you want more similar results to the paper then I would recommend manually changing the kimgs to 3000.

### Creating Synthetic Datasets

Once the training for the GAN has finished, then you should run the split_dataset bash file. This will create a directory that consists of synthetic images that comprise of 25% of the original dataset composition. Once this has completed, then run the move_real_data.py, which will then move 75% of the real data into the new folder.

__Note__: This repo currently only supports the option to have a 25% synthetic dataset. The paper tested the synthetic dataset on 25%, 50%, and 75% real:synthetic ratios. This may be updated in the future, but for now you will have to manually change the seed numbers and move_real_data values to test different ratios.

```
bash split_dataset.sh
bash move_real_data.py
```

### Evaluating Synthetic Datasets

When you have the synthetic datasets created you can now run the weightedtransformertrain.py file, which will run a Data Efficient Image Transformer model on the data and evaluate it on the 100% real dataset. The primary concern with training the model is that there is a severe class inbalance within the dataset.
